<!-- application.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <title>WhalaApp ‚Äî B-Eye-O-Marker V1 + WhalaBot</title>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="theme-color" content="#0b0b14"/>
  <meta name="description" content="Accessible AI: in-browser CNN eye screening (research, not diagnosis) + GPT-5 Mini assistive chatbot with planning, MCTS and TTS."/>
  <!-- Design language mirrors your index.html palette -->
  <style>
    :root{
      --bg:#0b0b14;--panel:#0f1120;--text:#f7f7fb;--muted:#b9b9c9;--brand:#7ad8ff;--violet:#b07cff;--accent:#64ffa1;--danger:#ff5a84;--focus:#ffe084;
      --card:rgba(255,255,255,.06);--shadow:0 18px 60px rgba(0,0,0,.45);--r:22px;--r2:30px
    }
    *{box-sizing:border-box}html,body{height:100%}body{
      margin:0;font-family:ui-sans-serif,system-ui,-apple-system,"Segoe UI",Roboto,Arial;color:var(--text);
      background:radial-gradient(1200px 800px at 10% -10%, rgba(122,216,255,.12), transparent 55%),
                 radial-gradient(1200px 800px at 110% 10%, rgba(176,124,255,.12), transparent 55%),
                 radial-gradient(900px 600px at 50% 120%, rgba(100,255,161,.08), transparent 60%),var(--bg);
    }
    header{position:sticky;top:0;z-index:10;backdrop-filter:saturate(1.2) blur(10px);background:linear-gradient(180deg, rgba(11,11,20,.78), rgba(11,11,20,.44));border-bottom:1px solid rgba(255,255,255,.06)}
    .nav{max-width:1200px;margin:0 auto;display:flex;align-items:center;justify-content:space-between;padding:12px 18px}
    .brand{display:flex;gap:10px;align-items:center;color:var(--text);text-decoration:none}
    .brand img{width:40px;height:40px;border-radius:10px;background:rgba(255,255,255,.05);padding:6px}
    main{max-width:1200px;margin:0 auto;padding:28px 18px 60px;display:grid;gap:24px}
    .grid{display:grid;grid-template-columns:1.1fr .9fr;gap:22px}
    .panel{background:linear-gradient(160deg, rgba(255,255,255,.06), rgba(255,255,255,.02));border:1px solid rgba(255,255,255,.1);border-radius:var(--r2);box-shadow:var(--shadow);padding:18px}
    h1{font-size:clamp(28px,4vw,40px);margin:6px 0 2px}
    h2{font-size:clamp(22px,3vw,28px);margin:0 0 8px}
    p.muted{color:var(--muted)}
    .row{display:flex;gap:10px;flex-wrap:wrap;align-items:center}
    .btn{border:1px solid rgba(255,255,255,.14);background:rgba(255,255,255,.06);color:var(--text);padding:10px 14px;border-radius:12px;cursor:pointer;font-weight:800}
    .btn:focus{outline:3px solid var(--focus);outline-offset:2px}
    input[type=file]{display:none}
    .upload-label{display:inline-flex;gap:10px;align-items:center}
    .stage{position:relative;border-radius:18px;background:var(--card);border:1px solid rgba(255,255,255,.1);min-height:280px;display:grid;place-items:center;overflow:hidden}
    video,canvas,.preview{max-width:100%;border-radius:12px}
    .metrics{display:grid;grid-template-columns:repeat(2,minmax(200px,1fr));gap:14px}
    .card{background:rgba(255,255,255,.04);border:1px solid rgba(255,255,255,.12);border-radius:16px;padding:14px}
    .status{font-family:ui-monospace,monospace}
    .pill{display:inline-block;padding:6px 10px;border-radius:999px;background:rgba(255,255,255,.08);border:1px solid rgba(255,255,255,.14);font-size:12px}
    .chat{display:grid;grid-template-rows:1fr auto;gap:10px;height:520px}
    .log{overflow:auto;border-radius:14px;background:rgba(255,255,255,.04);border:1px solid rgba(255,255,255,.1);padding:12px}
    .msg{margin:8px 0;padding:10px 12px;border-radius:12px}
    .msg.user{background:rgba(122,216,255,.10);border:1px solid rgba(122,216,255,.25)}
    .msg.bot{background:rgba(176,124,255,.10);border:1px solid rgba(176,124,255,.25)}
    textarea{width:100%;min-height:80px;border-radius:12px;border:1px solid rgba(255,255,255,.14);background:rgba(255,255,255,.04);color:var(--text);padding:10px}
    .foot{display:flex;gap:10px;align-items:center}
    .warn{color:#ffd8d8}
    .grid-2{display:grid;grid-template-columns:1fr 1fr;gap:22px}
    .sr-only{position:absolute;left:-9999px;top:auto;width:1px;height:1px;overflow:hidden}
    @media (max-width:1000px){.grid,.grid-2{grid-template-columns:1fr}}
  </style>

  <!-- ONNX Runtime Web: try WebGPU, fallback to WASM -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script>
  <script>window._ortLoadedAs='webgpu';</script>
  <script>
    // Fallback to WASM if WebGPU not supported or blocked
    if (!('gpu' in navigator)) {
      document.write('<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"><\/script>');
      window._ortLoadedAs='wasm';
    }
  </script>
  <!-- Chart.js for probability bars -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
</head>
<body>
<header>
  <nav class="nav" aria-label="Main">
    <a class="brand" href="index.html"><img src="logo.png" alt="Whala logo"/><strong>WhalaApp</strong></a>
    <div class="row">
      <button id="ttsAll" class="btn" aria-pressed="false" title="Toggle global TTS">üîä TTS</button>
      <button id="contrast" class="btn" aria-pressed="false">High Contrast</button>
      <button id="bigtext" class="btn" aria-pressed="false">A+ Text</button>
    </div>
  </nav>
</header>

<main>
  <section class="panel" aria-labelledby="app-h">
    <h1 id="app-h">B-Eye-O-Marker V1 + WhalaBot</h1>
    <p class="muted">Research prototype ‚Äî <strong>not a medical device</strong>. Results may be wrong. Always consult a clinician for diagnosis.</p>
  </section>

  <section class="grid" aria-labelledby="cnn-h">
    <!-- CNN PANEL -->
    <div class="panel" id="cnn-panel">
      <h2 id="cnn-h">B-Eye-O-Marker V1 (ONNX)</h2>
      <div class="row" role="group" aria-label="Image input">
        <label class="upload-label btn" for="file"><span>üìÅ Upload</span></label>
        <input id="file" type="file" accept="image/*" />
        <button id="cam" class="btn">üì∑ Camera</button>
        <button id="snap" class="btn" disabled>üü¢ Capture</button>
        <button id="analyze" class="btn" disabled>üß† Analyze</button>
        <span class="pill status" id="cnnStatus">model: loading‚Ä¶</span>
      </div>
      <div class="stage" id="stage" aria-live="polite">
        <video id="video" autoplay playsinline class="sr-only"></video>
        <canvas id="canvas" class="preview" aria-label="Image preview" width="224" height="224"></canvas>
      </div>

      <div class="metrics" style="margin-top:14px">
        <div class="card">
          <strong>Prediction</strong><br/>
          <div id="predText" style="margin-top:6px">‚Äî</div>
          <div class="muted" id="uncert">Uncertainty: ‚Äî</div>
        </div>
        <div class="card">
          <strong>Class Probabilities</strong>
          <canvas id="probChart" height="140" aria-label="Probability chart"></canvas>
        </div>
      </div>

      <div class="card" style="margin-top:14px">
        <strong>Manually specify condition (optional)</strong>
        <div class="row" style="margin-top:6px">
          <select id="manualCond" aria-label="Manual condition">
            <option value="">‚Äî None ‚Äî</option>
            <option>DR</option>
            <option>DME</option>
            <option>Normal</option>
          </select>
          <button id="applyManual" class="btn">Apply</button>
        </div>
        <p class="muted" style="margin:10px 0 0">If you don‚Äôt want to use the CNN, choose a condition here. This will feed the chatbot.</p>
      </div>
    </div>

    <!-- CHAT PANEL -->
    <div class="panel">
      <h2>WhalaBot (GPT-5 Mini)</h2>
      <p class="muted">Accessible assistant: takes CNN/Manual context + runs an internal MCTS plan, then explains options in plain language. Auto-TTS is on when üîä is active.</p>
      <div class="chat">
        <div id="log" class="log" role="log" aria-live="polite" aria-relevant="additions"></div>
        <div class="foot">
          <textarea id="input" placeholder="Ask anything‚Ä¶ e.g., ‚ÄúWhat should I do next?‚Äù"></textarea>
          <button id="send" class="btn">Send</button>
        </div>
        <div class="warn" role="note">Safety: This is not medical advice. If you have sudden vision loss, flashes, or a ‚Äòcurtain‚Äô over vision ‚Äî seek emergency care.</div>
      </div>
    </div>
  </section>

  <section class="panel">
    <h2>Deep Metrics & Accessibility Insights</h2>
    <div class="grid-2">
      <div class="card">
        <strong>Report Elements</strong>
        <ul id="reportList" aria-live="polite">
          <li>Summary</li>
          <li>Top actions (from MCTS)</li>
          <li>Follow-up timeline</li>
          <li>Accessibility plan (TTS, screen reader, contrast, magnification)</li>
        </ul>
      </div>
      <div class="card">
        <strong>Explain-Like-I‚Äôm-Listening (ELL)</strong>
        <p class="muted">Every section is narrated when üîä is on. For low-vision users, diagrams are described with text and earcons.</p>
      </div>
    </div>
  </section>
</main>

<script>
/* =========================
   GLOBAL A11Y + TTS
========================= */
const ttsToggle = document.getElementById('ttsAll');
let ttsOn = JSON.parse(localStorage.getItem('whala_tts') || 'true');
const synth = window.speechSynthesis;
function speak(text) {
  if (!ttsOn) return;
  if (!text) return;
  // Cancel previous utterances to avoid queue buildup
  synth.cancel();
  const u = new SpeechSynthesisUtterance(text);
  u.rate = 1.02; u.pitch = 1.0; u.volume = 1.0;
  // Prefer an English voice; let OS pick best available.
  const voice = (synth.getVoices() || []).find(v => /en-|English/i.test(v.name));
  if (voice) u.voice = voice;
  synth.speak(u);
}
function setTTSEnabled(v) {
  ttsOn = v; localStorage.setItem('whala_tts', JSON.stringify(v));
  ttsToggle.setAttribute('aria-pressed', v);
}
setTTSEnabled(ttsOn);
ttsToggle.addEventListener('click', ()=> setTTSEnabled(!ttsOn));

document.getElementById('contrast').addEventListener('click', (e)=>{
  const pressed = e.currentTarget.getAttribute('aria-pressed') === 'true';
  e.currentTarget.setAttribute('aria-pressed', String(!pressed));
  document.documentElement.style.setProperty('--bg', pressed ? '#0b0b14' : '#000');
  document.documentElement.style.setProperty('--text', pressed ? '#f7f7fb' : '#fff');
  document.documentElement.style.setProperty('--muted', pressed ? '#b9b9c9' : '#eaeaea');
  speak('High contrast ' + (!pressed ? 'enabled' : 'disabled'));
});
document.getElementById('bigtext').addEventListener('click', (e)=>{
  const pressed = e.currentTarget.getAttribute('aria-pressed') === 'true';
  e.currentTarget.setAttribute('aria-pressed', String(!pressed));
  document.body.style.fontSize = pressed ? '' : '18px';
  speak('Large text ' + (!pressed ? 'enabled' : 'disabled'));
});

/* =========================
   CNN INFERENCE (ONNX)
   - tries WebGPU, falls back to WASM
   - preprocessing: grayscale, 224x224, [0,1]
========================= */
// ONNX Runtime Web references (WebGPU/WASM usage): official docs
// - Execution provider switch via webgpu script vs default WASM build
// - Web env/session flags & wasmPaths if you self-host assets (we use CDN) :contentReference[oaicite:4]{index=4}
const ortReady = new Promise((resolve)=>{
  if (window._ortLoadedAs === 'webgpu') {
    // nothing else needed; WebGPU is active if available
    resolve();
  } else {
    // WASM path already handled by CDN; resolve immediately
    resolve();
  }
});
let session = null;
let probChart = null;
const cnnStatus = document.getElementById('cnnStatus');
const canvas = document.getElementById('canvas');
const ctx2d = canvas.getContext('2d', { willReadFrequently: true });

async function loadModel() {
  await ortReady;
  cnnStatus.textContent = 'model: loading‚Ä¶';
  // For WebGPU, sessionOptions can specify executionProviders: ['webgpu']
  // For WASM default: no need to set EP explicitly.
  session = await ort.InferenceSession.create('./b_eye_o_marker_v1.onnx', {
    executionProviders: ('gpu' in navigator && window._ortLoadedAs==='webgpu') ? ['webgpu','wasm'] : ['wasm'],
    graphOptimizationLevel: 'all'
  });
  cnnStatus.textContent = 'model: ready';
  speak('Vision model loaded and ready.');
}
loadModel().catch(e => { cnnStatus.textContent = 'model: error'; console.error(e); });

function drawToCanvasFromImage(img){
  // Fit into 224x224 while covering (center-crop)
  const size = 224; canvas.width=size; canvas.height=size;
  const r = img.width / img.height;
  let dw=size, dh=size, sx=0, sy=0, sw=img.width, sh=img.height;
  if (r>1){ // wider
    sh = img.height; sw = sh; sx = (img.width - sw)/2;
  } else { // taller
    sw = img.width; sh = sw; sy = (img.height - sh)/2;
  }
  ctx2d.clearRect(0,0,size,size);
  ctx2d.drawImage(img, sx, sy, sw, sh, 0,0,size,size);
}
function tensorFromCanvas(){
  const { data } = ctx2d.getImageData(0,0,224,224);
  const out = new Float32Array(1*1*224*224);
  // Convert RGBA -> gray, normalize [0,1]
  for (let i=0, j=0; i<data.length; i+=4, j++){
    const r=data[i], g=data[i+1], b=data[i+2];
    out[j] = (0.299*r + 0.587*g + 0.114*b)/255;
  }
  return new ort.Tensor('float32', out, [1,1,224,224]);
}

const file = document.getElementById('file');
file.addEventListener('change', (e)=>{
  const f = e.target.files?.[0]; if (!f) return;
  const img = new Image(); img.onload = ()=>{ drawToCanvasFromImage(img); setAnalyzeEnabled(true); };
  img.src = URL.createObjectURL(f);
});
const video = document.getElementById('video');
const camBtn = document.getElementById('cam');
const snapBtn = document.getElementById('snap');
camBtn.addEventListener('click', async ()=>{
  try{
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode:'user', width: 640, height: 480 } });
    video.srcObject = stream; video.classList.remove('sr-only');
    snapBtn.disabled = false; speak('Camera ready. Center your eye and press capture.');
  }catch(err){
    alert('Camera not available.'); console.error(err);
  }
});
snapBtn.addEventListener('click', ()=>{
  const v = video;
  if (!v || v.readyState < 2) return;
  canvas.getContext('2d').drawImage(v, 0,0,224,224);
  video.classList.add('sr-only');
  setAnalyzeEnabled(true);
});
const analyzeBtn = document.getElementById('analyze');
function setAnalyzeEnabled(v){ analyzeBtn.disabled = !v; }
let lastCnn = null;

async function runCNN(){
  if (!session){ alert('Model not ready yet.'); return; }
  cnnStatus.textContent = 'analyzing‚Ä¶';
  const input = tensorFromCanvas();
  const outputs = await session.run({ input });
  const logits = outputs.logits?.data || Object.values(outputs)[0].data; // [N,2]
  const [logit0, logit1] = [logits[0], logits[1]];
  // Softmax
  const e0 = Math.exp(logit0 - Math.max(logit0, logit1));
  const e1 = Math.exp(logit1 - Math.max(logit0, logit1));
  const s = e0 + e1;
  const p0 = e0 / s, p1 = e1 / s;

  // Map: 0->DR, 1->DME (from training convention)
  const label = (p0 >= p1) ? 'DR' : 'DME';
  const conf = Math.max(p0, p1);
  const uncert = 1 - conf;

  lastCnn = { label: label.toLowerCase(), probs:{ DR:p0, DME:p1 }, confidence: conf, uncertainty: uncert,
              severity: conf>0.8 ? 'severe' : conf>0.6 ? 'moderate' : 'mild' };

  updateUI(lastCnn);
  cnnStatus.textContent = 'done';
  speak(`Model thinks: ${label}, confidence ${(conf*100).toFixed(0)} percent.`);
}
analyzeBtn.addEventListener('click', runCNN);

// Chart + UI updates
const probCtx = document.getElementById('probChart');
probChart = new Chart(probCtx, {
  type:'bar',
  data:{ labels:['DR','DME'], datasets:[{ label:'Probability', data:[0,0] }] },
  options:{ responsive:true, plugins:{ legend:{ display:false } }, scales:{ y:{ min:0, max:1 } } }
});
const predText = document.getElementById('predText');
const uncert = document.getElementById('uncert');

function updateUI(cnn){
  probChart.data.datasets[0].data = [cnn.probs.DR, cnn.probs.DME];
  probChart.update();
  predText.textContent = `Pred: ${cnn.label.toUpperCase()}  (conf ${(cnn.confidence*100).toFixed(1)}%)`;
  uncert.textContent = `Uncertainty: ${(cnn.uncertainty*100).toFixed(1)}%`;
  addReport([
    `CNN suggests: ${cnn.label.toUpperCase()}`,
    `Confidence: ${(cnn.confidence*100).toFixed(1)}%`,
    `Severity bucket: ${cnn.severity}`
  ]);
}

// Manual condition override
const manualSel = document.getElementById('manualCond');
document.getElementById('applyManual').addEventListener('click', ()=>{
  const v = manualSel.value;
  if (!v){ speak('Manual condition cleared.'); return; }
  lastCnn = { label: v.toLowerCase(), probs:{ DR: v==='DR'?1:0, DME: v==='DME'?1:0 }, confidence: 0.5, uncertainty: 0.5, severity:'moderate' };
  updateUI(lastCnn);
  speak(`Manual condition set to ${v}.`);
});

/* =========================
   CHATBOT (server proxy -> OpenAI)
========================= */
const log = document.getElementById('log');
const input = document.getElementById('input');
const send = document.getElementById('send');
let history = [];

function addMsg(role, text){
  const div = document.createElement('div');
  div.className = `msg ${role}`;
  div.textContent = text;
  log.appendChild(div);
  log.scrollTop = log.scrollHeight;
  if (role === 'bot') speak(text);
}

function addReport(items){
  const ul = document.getElementById('reportList');
  for (const it of items){
    const li = document.createElement('li'); li.textContent = it; ul.appendChild(li);
  }
}

async function chatSend(){
  const content = input.value.trim(); if (!content) return;
  input.value = '';
  history.push({ role:'user', content });
  addMsg('user', content);

  const body = { messages: history, cnn: lastCnn, manual_condition: manualSel.value || null, user_prefs: { tts: ttsOn } };
  const res = await fetch('/api/chat', {
    method:'POST',
    headers:{ 'Content-Type':'application/json' },
    body: JSON.stringify(body)
  });
  const data = await res.json();
  if (!data.ok){ addMsg('bot', 'Sorry, something went wrong.'); return; }
  const text = data.text;
  history.push({ role:'assistant', content: text });
  addMsg('bot', text);
  // surface the plan items too
  if (Array.isArray(data.plan) && data.plan.length) {
    addReport(['Top actions (MCTS):', ...data.plan.map(x=>'‚Ä¢ '+x)]);
  }
}

send.addEventListener('click', chatSend);
input.addEventListener('keydown', (e)=>{ if (e.key==='Enter' && !e.shiftKey) { e.preventDefault(); chatSend(); }});

// Narrate initial load
speak('Whala application loaded. Use upload or camera, then press Analyze. Open the chat to get guidance.');

/* Small a11y: auto focus log region on new bot messages for screen readers */
const observer = new MutationObserver(()=> log.setAttribute('tabindex','-1'));
observer.observe(log, { childList:true });

</script>
</body>
</html>
