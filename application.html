<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <title>WhalaApp ‚Äî Local (WebLLM + ONNX, No API)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="theme-color" content="#0b0b14"/>
  <meta name="description" content="All-local WhalaApp: on-device LLM (WebLLM) + on-device CNN (ONNX Runtime Web). No backend, no keys."/>
  <style>
    :root{
      --bg:#0b0b14;--panel:#0f1120;--text:#f7f7fb;--muted:#b9b9c9;--brand:#7ad8ff;--violet:#b07cff;--accent:#64ffa1;--danger:#ff5a84;--focus:#ffe084;
      --card:rgba(255,255,255,.06);--shadow:0 18px 60px rgba(0,0,0,.45);--r:22px;--r2:30px
    }
    *{box-sizing:border-box}html,body{height:100%}
    body{
      margin:0;font-family:ui-sans-serif,system-ui,-apple-system,"Segoe UI",Roboto,Arial;color:var(--text);
      background:
        radial-gradient(1200px 800px at 10% -10%, rgba(122,216,255,.12), transparent 55%),
        radial-gradient(1200px 800px at 110% 10%, rgba(176,124,255,.12), transparent 55%),
        radial-gradient(900px 600px at 50% 120%, rgba(100,255,161,.08), transparent 60%),var(--bg)
    }
    header{position:sticky;top:0;z-index:10;backdrop-filter:saturate(1.2) blur(10px);background:linear-gradient(180deg, rgba(11,11,20,.78), rgba(11,11,20,.44));border-bottom:1px solid rgba(255,255,255,.06)}
    .nav{max-width:1200px;margin:0 auto;display:flex;align-items:center;justify-content:space-between;padding:12px 18px}
    .brand{display:flex;gap:10px;align-items:center;color:var(--text);text-decoration:none}
    .brand img{width:40px;height:40px;border-radius:10px;background:rgba(255,255,255,.05);padding:6px}
    main{max-width:1200px;margin:0 auto;padding:28px 18px 60px;display:grid;gap:24px}
    .grid{display:grid;grid-template-columns:1.1fr .9fr;gap:22px}
    .panel{background:linear-gradient(160deg, rgba(255,255,255,.06), rgba(255,255,255,.02));border:1px solid rgba(255,255,255,.1);border-radius:var(--r2);box-shadow:var(--shadow);padding:18px}
    h1{font-size:clamp(28px,4vw,40px);margin:6px 0 2px}
    h2{font-size:clamp(22px,3vw,28px);margin:0 0 8px}
    p.muted{color:var(--muted)}
    .row{display:flex;gap:10px;flex-wrap:wrap;align-items:center}
    .btn{border:1px solid rgba(255,255,255,.14);background:rgba(255,255,255,.06);color:var(--text);padding:10px 14px;border-radius:12px;cursor:pointer;font-weight:800}
    .btn:focus{outline:3px solid var(--focus);outline-offset:2px}
    input[type=file]{display:none}
    .upload-label{display:inline-flex;gap:10px;align-items:center}
    .stage{position:relative;border-radius:18px;background:var(--card);border:1px solid rgba(255,255,255,.1);min-height:280px;display:grid;place-items:center;overflow:hidden}
    video,canvas,.preview{max-width:100%;border-radius:12px}
    .metrics{display:grid;grid-template-columns:repeat(2,minmax(200px,1fr));gap:14px}
    .card{background:rgba(255,255,255,.04);border:1px solid rgba(255,255,255,.12);border-radius:16px;padding:14px}
    .status{font-family:ui-monospace,monospace}
    .pill{display:inline-block;padding:6px 10px;border-radius:999px;background:rgba(255,255,255,.08);border:1px solid rgba(255,255,255,.14);font-size:12px}
    .chat{display:grid;grid-template-rows:1fr auto;gap:10px;height:520px}
    .log{overflow:auto;border-radius:14px;background:rgba(255,255,255,.04);border:1px solid rgba(255,255,255,.1);padding:12px}
    .msg{margin:8px 0;padding:10px 12px;border-radius:12px}
    .msg.user{background:rgba(122,216,255,.10);border:1px solid rgba(122,216,255,.25)}
    .msg.bot{background:rgba(176,124,255,.10);border:1px solid rgba(176,124,255,.25)}
    textarea{width:100%;min-height:80px;border-radius:12px;border:1px solid rgba(255,255,255,.14);background:rgba(255,255,255,.04);color:var(--text);padding:10px}
    .foot{display:flex;gap:10px;align-items:center}
    .warn{color:#ffd8d8}
    .grid-2{display:grid;grid-template-columns:1fr 1fr;gap:22px}
    .sr-only{position:absolute;left:-9999px;top:auto;width:1px;height:1px;overflow:hidden}
    @media (max-width:1000px){.grid,.grid-2{grid-template-columns:1fr}}
  </style>

  <!-- ONNX Runtime Web: WebGPU first, WASM fallback -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script>
  <script>window._ortLoadedAs='webgpu';</script>
  <script>
    if (!('gpu' in navigator)) {
      document.write('<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"><\/script>');
      window._ortLoadedAs='wasm';
    }
  </script>
  <!-- Chart.js for probability bars -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
  <!-- WebLLM (on-device LLM, no key, no backend) -->
  <script src="https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.49/dist/web-llm.min.js"></script>
</head>
<body>
<header>
  <nav class="nav" aria-label="Main">
    <a class="brand" href="index.html"><img src="logo.png" alt="Whala logo"/><strong>WhalaApp (Local)</strong></a>
    <div class="row">
      <button id="ttsAll" class="btn" aria-pressed="false" title="Toggle global TTS">üîä TTS</button>
      <button id="contrast" class="btn" aria-pressed="false">High Contrast</button>
      <button id="bigtext" class="btn" aria-pressed="false">A+ Text</button>
    </div>
  </nav>
</header>

<main>
  <section class="panel" aria-labelledby="app-h">
    <h1 id="app-h">B-Eye-O-Marker V1 + WhalaBot (Local)</h1>
    <p class="muted">Research demo ‚Äî <strong>not a medical device</strong>. Results may be wrong. Always consult a clinician.</p>
  </section>

  <section class="grid" aria-labelledby="cnn-h">
    <!-- CNN PANEL -->
    <div class="panel" id="cnn-panel">
      <h2 id="cnn-h">B-Eye-O-Marker V1 (ONNX, local)</h2>
      <div class="row" role="group" aria-label="Image input">
        <label class="upload-label btn" for="file"><span>üìÅ Upload</span></label>
        <input id="file" type="file" accept="image/*" />
        <button id="cam" class="btn">üì∑ Camera</button>
        <button id="snap" class="btn" disabled>üü¢ Capture</button>
        <button id="analyze" class="btn" disabled>üß† Analyze</button>
        <span class="pill status" id="cnnStatus">model: loading‚Ä¶</span>
      </div>
      <div class="stage" id="stage" aria-live="polite">
        <video id="video" autoplay playsinline class="sr-only"></video>
        <canvas id="canvas" class="preview" aria-label="Image preview" width="224" height="224"></canvas>
      </div>

      <div class="metrics" style="margin-top:14px">
        <div class="card">
          <strong>Prediction</strong><br/>
          <div id="predText" style="margin-top:6px">‚Äî</div>
          <div class="muted" id="uncert">Uncertainty: ‚Äî</div>
        </div>
        <div class="card">
          <strong>Class Probabilities</strong>
          <canvas id="probChart" height="140" aria-label="Probability chart"></canvas>
        </div>
      </div>

      <div class="card" style="margin-top:14px">
        <strong>Manually specify condition (optional)</strong>
        <div class="row" style="margin-top:6px">
          <select id="manualCond" aria-label="Manual condition">
            <option value="">‚Äî None ‚Äî</option>
            <option>DR</option>
            <option>DME</option>
            <option>Normal</option>
          </select>
          <button id="applyManual" class="btn">Apply</button>
        </div>
        <p class="muted" style="margin:10px 0 0">If you don‚Äôt want to use the CNN, choose a condition here. This will feed the local chatbot.</p>
      </div>
    </div>

    <!-- CHAT PANEL -->
    <div class="panel">
      <h2>WhalaBot (Local WebLLM)</h2>
      <p class="muted">Runs 100% on your device. No internet calls. Auto-TTS speaks all responses when üîä is on.</p>
      <div class="chat">
        <div id="log" class="log" role="log" aria-live="polite" aria-relevant="additions"></div>
        <div class="foot">
          <textarea id="input" placeholder="Ask anything‚Ä¶ e.g., ‚ÄúWhat should I do next?‚Äù"></textarea>
          <button id="send" class="btn" disabled>Loading model‚Ä¶</button>
        </div>
        <div class="warn" role="note">This is not medical advice. Emergencies (sudden vision loss, flashes, ‚Äòcurtain‚Äô) ‚Üí seek urgent care.</div>
      </div>
    </div>
  </section>

  <section class="panel">
    <h2>Deep Metrics & Accessibility Insights</h2>
    <div class="grid-2">
      <div class="card">
        <strong>Report Elements</strong>
        <ul id="reportList" aria-live="polite">
          <li>Summary</li>
          <li>Top actions (from MCTS)</li>
          <li>Follow-up timeline</li>
          <li>Accessibility plan (TTS, screen reader, contrast, magnification)</li>
        </ul>
      </div>
      <div class="card">
        <strong>Explain-Like-I‚Äôm-Listening (ELL)</strong>
        <p class="muted">Every section is narrated when üîä is on. For low-vision users, diagrams are described with words and earcons.</p>
      </div>
    </div>
  </section>
</main>

<script>
/* ===========================================================
   DOMContentLoaded ensures all elements exist before we start.
   This also prevents "Cannot access 'log' before initialization".
=========================================================== */
window.addEventListener('DOMContentLoaded', () => {
/* =========================
   GLOBAL A11Y + TTS
========================= */
const ttsToggle = document.getElementById('ttsAll');
let ttsOn = JSON.parse(localStorage.getItem('whala_tts') || 'true');
const synth = window.speechSynthesis;
let chosenVoice = null;
function pickVoice(){
  const vs = synth.getVoices();
  chosenVoice = vs.find(v => /English|en-/i.test(v.name)) || vs[0] || null;
}
if (synth.onvoiceschanged !== undefined) synth.onvoiceschanged = pickVoice; pickVoice();

function speak(text) {
  if (!ttsOn || !text) return;
  try {
    const u = new SpeechSynthesisUtterance(text);
    u.rate = 1.02; u.pitch = 1.0; u.volume = 1.0;
    if (chosenVoice) u.voice = chosenVoice;
    synth.speak(u);
  } catch {}
}
function setTTSEnabled(v) {
  ttsOn = v; localStorage.setItem('whala_tts', JSON.stringify(v));
  ttsToggle.setAttribute('aria-pressed', v);
}
setTTSEnabled(ttsOn);
ttsToggle.addEventListener('click', ()=> setTTSEnabled(!ttsOn));

document.getElementById('contrast').addEventListener('click', (e)=>{
  const pressed = e.currentTarget.getAttribute('aria-pressed') === 'true';
  e.currentTarget.setAttribute('aria-pressed', String(!pressed));
  document.documentElement.style.setProperty('--bg', pressed ? '#0b0b14' : '#000');
  document.documentElement.style.setProperty('--text', pressed ? '#f7f7fb' : '#fff');
  document.documentElement.style.setProperty('--muted', pressed ? '#b9b9c9' : '#eaeaea');
  speak('High contrast ' + (!pressed ? 'enabled' : 'disabled'));
});
document.getElementById('bigtext').addEventListener('click', (e)=>{
  const pressed = e.currentTarget.getAttribute('aria-pressed') === 'true';
  e.currentTarget.setAttribute('aria-pressed', String(!pressed));
  document.body.style.fontSize = pressed ? '' : '18px';
  speak('Large text ' + (!pressed ? 'enabled' : 'disabled'));
});

/* =========================
   CNN INFERENCE (ONNX)
========================= */
let session = null;
let probChart = null;
const cnnStatus = document.getElementById('cnnStatus');
const canvas = document.getElementById('canvas');
const ctx2d = canvas.getContext('2d', { willReadFrequently: true });

async function loadModel() {
  try{
    cnnStatus.textContent = 'model: loading‚Ä¶';
    session = await ort.InferenceSession.create('./b_eye_o_marker_v1.onnx', {
      executionProviders: ('gpu' in navigator && window._ortLoadedAs==='webgpu') ? ['webgpu','wasm'] : ['wasm'],
      graphOptimizationLevel: 'all'
    });
    cnnStatus.textContent = 'model: ready';
    speak('Vision model loaded and ready.');
  }catch(e){
    cnnStatus.textContent = 'model: error';
    console.error(e);
    speak('Vision model failed to load.');
  }
}
loadModel();

function drawToCanvasFromImage(img){
  const size = 224; canvas.width=size; canvas.height=size;
  const r = img.width / img.height;
  let sx=0, sy=0, sw=img.width, sh=img.height;
  if (r>1){ sh = img.height; sw = sh; sx = (img.width - sw)/2; } else { sw = img.width; sh = sw; sy = (img.height - sh)/2; }
  ctx2d.clearRect(0,0,size,size);
  ctx2d.drawImage(img, sx, sy, sw, sh, 0,0,size,size);
}
function tensorFromCanvas(){
  const { data } = ctx2d.getImageData(0,0,224,224);
  const out = new Float32Array(1*1*224*224);
  for (let i=0, j=0; i<data.length; i+=4, j++){
    const r=data[i], g=data[i+1], b=data[i+2];
    out[j] = (0.299*r + 0.587*g + 0.114*b)/255;
  }
  return new ort.Tensor('float32', out, [1,1,224,224]);
}

const file = document.getElementById('file');
file.addEventListener('change', (e)=>{
  const f = e.target.files?.[0]; if (!f) return;
  const img = new Image(); img.onload = ()=>{ drawToCanvasFromImage(img); setAnalyzeEnabled(true); };
  img.src = URL.createObjectURL(f);
});

const video = document.getElementById('video');
const camBtn = document.getElementById('cam');
const snapBtn = document.getElementById('snap');
camBtn.addEventListener('click', async ()=>{
  try{
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode:'user', width: 640, height: 480 } });
    video.srcObject = stream; video.classList.remove('sr-only');
    snapBtn.disabled = false; speak('Camera ready. Center your eye and press capture.');
  }catch(err){
    alert('Camera not available.'); console.error(err);
  }
});
snapBtn.addEventListener('click', ()=>{
  if (!video || video.readyState < 2) return;
  canvas.getContext('2d').drawImage(video, 0,0,224,224);
  video.classList.add('sr-only');
  setAnalyzeEnabled(true);
});

const analyzeBtn = document.getElementById('analyze');
function setAnalyzeEnabled(v){ analyzeBtn.disabled = !v; }
let lastCnn = null;

async function runCNN(){
  if (!session){ alert('Model not ready yet.'); return; }
  cnnStatus.textContent = 'analyzing‚Ä¶';
  const input = tensorFromCanvas();
  const outputs = await session.run({ input });
  const outArr = outputs.logits?.data || Object.values(outputs)[0].data; // [2]
  const [l0, l1] = [outArr[0], outArr[1]];
  const m = Math.max(l0,l1);
  const e0 = Math.exp(l0-m), e1 = Math.exp(l1-m);
  const s = e0+e1, p0=e0/s, p1=e1/s;
  const label = (p0>=p1)?'DR':'DME';
  const conf = Math.max(p0,p1), uncert=1-conf;
  lastCnn = { label: label.toLowerCase(), probs:{ DR:p0, DME:p1 }, confidence: conf, uncertainty: uncert,
              severity: conf>0.8 ? 'severe' : conf>0.6 ? 'moderate' : 'mild' };
  updateUI(lastCnn);
  cnnStatus.textContent = 'done';
  speak(`Model thinks: ${label}, confidence ${(conf*100).toFixed(0)} percent.`);
}
analyzeBtn.addEventListener('click', runCNN);

// Chart + UI updates
const probCtx = document.getElementById('probChart');
probChart = new Chart(probCtx, {
  type:'bar',
  data:{ labels:['DR','DME'], datasets:[{ label:'Probability', data:[0,0] }] },
  options:{ responsive:true, plugins:{ legend:{ display:false } }, scales:{ y:{ min:0, max:1 } } }
});
const predText = document.getElementById('predText');
const uncert = document.getElementById('uncert');
function updateUI(cnn){
  probChart.data.datasets[0].data = [cnn.probs.DR, cnn.probs.DME];
  probChart.update();
  predText.textContent = `Pred: ${cnn.label.toUpperCase()}  (conf ${(cnn.confidence*100).toFixed(1)}%)`;
  uncert.textContent = `Uncertainty: ${(cnn.uncertainty*100).toFixed(1)}%`;
  addReport([
    `CNN suggests: ${cnn.label.toUpperCase()}`,
    `Confidence: ${(cnn.confidence*100).toFixed(1)}%`,
    `Severity bucket: ${cnn.severity}`
  ]);
}
// Manual condition override
const manualSel = document.getElementById('manualCond');
document.getElementById('applyManual').addEventListener('click', ()=>{
  const v = manualSel.value;
  if (!v){ speak('Manual condition cleared.'); return; }
  lastCnn = { label: v.toLowerCase(), probs:{ DR: v==='DR'?1:0, DME: v==='DME'?1:0 }, confidence: 0.5, uncertainty: 0.5, severity:'moderate' };
  updateUI(lastCnn);
  speak(`Manual condition set to ${v}.`);
});
document.getElementById('analyze').disabled = true;

/* =========================
   MCTS (client-side)
========================= */
class MCTSNode{constructor(state,parent=null,action=null){this.state=state;this.parent=parent;this.action=action;this.children=[];this.visits=0;this.value=0}}
const ACTIONS=[
  {key:'book_ophthalmology',cost:2,benefit:9,text:'Book an ophthalmology appointment (1‚Äì2 weeks)'},
  {key:'urgent',cost:3,benefit:12,text:'Urgent care if flashes, curtain, severe pain'},
  {key:'oct_fu',cost:2,benefit:8,text:'OCT follow-up imaging (6‚Äì8 weeks)'},
  {key:'glycemic',cost:1,benefit:7,text:'Tighten glycemic & BP control with reminders'},
  {key:'a11y',cost:1,benefit:6,text:'Enable screen reader, large text, high contrast'},
  {key:'tts',cost:1,benefit:6,text:'Use TTS everywhere and voice control'},
  {key:'lowvision',cost:2,benefit:7,text:'Magnifier tools, contrast themes, ergonomics'}
];
function rewardFor(state,action){const {condition='unknown',severity='moderate'}=state;const sev=severity==='severe'?1.4:severity==='mild'?0.9:1.0;const w=(k)=>({dr:{book_ophthalmology:10,oct_fu:8,glycemic:7},dme:{book_ophthalmology:10,oct_fu:8,glycemic:7},normal:{a11y:6,tts:6,lowvision:6}}[condition]?.[k]??5);return (action.benefit-action.cost)*sev+w(action.key)}
function expand(node){const used=new Set(node.state.plan?.map(p=>p.key));const opts=ACTIONS.filter(a=>!used.has(a.key));if(!opts.length)return null;const pick=opts[Math.floor(Math.random()*opts.length)];const next=new MCTSNode({...node.state,stepIndex:(node.state.stepIndex||0)+1,plan:[...(node.state.plan||[]),pick]},node,pick);node.children.push(next);return next}
function simulate(state){let tot=0;let used=new Set(state.plan?.map(p=>p.key));for(let i=0;i<4;i++){const opts=ACTIONS.filter(a=>!used.has(a.key));if(!opts.length)break;const a=opts[Math.floor(Math.random()*opts.length)];tot+=rewardFor(state,a);used.add(a.key)}return tot/4}
function backprop(n,v){while(n){n.visits+=1;n.value+=v;n=n.parent}}
function bestChildByUCT(n){let b=null,uBest=-Infinity;for(const c of n.children){const u=(c.visits===0)?Infinity:(c.value/c.visits)+1.4*Math.sqrt(Math.log(Math.max(1,n.visits))/c.visits);if(u>uBest){uBest=u;b=c}}return b}
function runMCTS({condition,severity,prefs},iters=220){const root=new MCTSNode({condition,severity,prefs,plan:[]});for(let i=0;i<iters;i++){let node=root;while(node.children.length>0) node=bestChildByUCT(node);node=expand(node)||node;const v=simulate(node.state);backprop(node,v)}let best=null,score=-Infinity;for(const c of root.children){const s=c.value/Math.max(1,c.visits);if(s>score){score=s;best=c}}return (best?.state.plan||[]).map(a=>a.text)}

/* =========================
   CHAT UI (pure local)
========================= */
const log = document.getElementById('log');
const input = document.getElementById('input');
const send = document.getElementById('send');
let history = [];

function addMsg(role, text){
  const div = document.createElement('div');
  div.className = `msg ${role}`;
  div.textContent = text;
  log.appendChild(div);
  log.scrollTop = log.scrollHeight;
  if (role === 'bot') speak(text);
}
function addReport(items){
  const ul = document.getElementById('reportList');
  for (const it of items){
    const li = document.createElement('li'); li.textContent = it; ul.appendChild(li);
  }
}

async function chatSend(){
  const content = input.value.trim(); if (!content) return;
  input.value = '';
  history.push({ role:'user', content });
  addMsg('user', content);

  if (!webllmReady){
    addMsg('bot', 'Local model is still loading. Please wait a moment and try again.');
    return;
  }

  const condition = (manualSel.value || lastCnn?.label || 'unknown').toLowerCase();
  const severity  = lastCnn?.severity || 'moderate';
  const plan      = runMCTS({ condition, severity, prefs:{ tts: ttsOn } }, 260);
  const system = [
    "Role: Assistive health & accessibility guide. You are not a doctor; do NOT provide medical diagnoses.",
    "Always recommend professional care; escalate emergencies (sudden vision loss, flashes, curtain).",
    "Use CNN or manual context cautiously; it may be wrong. Express uncertainty and alternatives.",
    "Accessibility first: concise summary, numbered steps, long-form details, TL;DR, describe visuals.",
    "Tone: calm, clear, empowering. Explain jargon. No data retention."
  ].join(' ');

  const ctx = {
    cnn_summary: lastCnn || null,
    assumed_condition: condition,
    mcts_candidate_plan: plan
  };

  let text = '';
  try {
    if (webllmEngine?.chat?.completions?.create) {
      const out = await webllmEngine.chat.completions.create({
        messages: [
          { role:'system', content: system },
          { role:'user', content: "JSON context:\n" + JSON.stringify(ctx, null, 2) },
          ...history
        ],
        temperature: 0.3,
        max_tokens: 700,
        stream: false
      });
      text = out.choices?.[0]?.message?.content || '';
    } else if (webllmEngine?.generate) {
      const prompt = [
        system,
        "\n---\nContext JSON:\n", JSON.stringify(ctx, null, 2),
        "\n---\nUser message:\n", content,
        "\n---\nAssistant (clear, stepwise, accessible):\n"
      ].join('');
      const out = await webllmEngine.generate(prompt);
      text = out?.output_text || out || '';
    } else {
      text = 'Local model API not available in this browser build.';
    }
  } catch (err) {
    console.error(err);
    text = 'Local model error. Try reloading the page.';
  }

  if (!text) text = 'Sorry, the local model could not produce a response.';
  history.push({ role:'assistant', content: text });
  addMsg('bot', text);
  if (Array.isArray(plan) && plan.length) addReport(['Top actions (MCTS):', ...plan.map(x=>'‚Ä¢ '+x)]);
}

send.addEventListener('click', chatSend);
input.addEventListener('keydown', (e)=>{ if (e.key==='Enter' && !e.shiftKey) { e.preventDefault(); chatSend(); }});

// Initial narration & tiny a11y nicety
addMsg('bot', 'Local Whala application loaded. Use upload or camera, then press Analyze. Chat is fully local.');
const observer = new MutationObserver(()=> log.setAttribute('tabindex','-1'));
observer.observe(log, { childList:true });

/* =========================
   WebLLM (local LLM) ‚Äî load AFTER UI is ready
========================= */
let webllmReady = false;
let webllmEngine = null;
const WEBLLM_MODEL = "Llama-3.2-1B-Instruct-q4f16_1-MLC";

async function initWebLLM(){
  try {
    const { CreateMLCEngine } = window.webllm;
    send.disabled = true; send.textContent = 'Loading model‚Ä¶';

    webllmEngine = await CreateMLCEngine(WEBLLM_MODEL, {
      gpuMemoryUsage: 0.9,
      appConfig: { temperature: 0.3, top_p: 0.9 },
      logLevel: "warn",
      initProgressCallback: (p) => {
        if (p && typeof p.progress === 'number') {
          const pct = Math.round(p.progress*100);
          send.textContent = `Loading model‚Ä¶ ${pct}%`;
          // reuse the status pill to show LLM progress too
          cnnStatus.textContent = `LLM: ${pct}%`;
        }
      }
    });

    webllmReady = true;
    send.disabled = false; send.textContent = 'Send';
    cnnStatus.textContent = 'LLM: ready';
    addMsg('bot', 'Local chatbot ready. Ask anything, or Analyze an image first for context.');
    speak('Local chatbot is ready.');
  } catch (e) {
    console.warn("WebLLM init failed", e);
    addMsg('bot', 'Local model failed to load. Try refreshing the page.');
  }
}
initWebLLM();

/* Enable Analyze only after an image or capture exists */
function hasPixels(){
  const d = ctx2d.getImageData(0,0,224,224).data;
  for (let i=0;i<64;i++){ if (d[i]!==0) return true; } // quick peek
  return false;
}
canvas.addEventListener('update', ()=> setAnalyzeEnabled(hasPixels()));
// Also enable after file/cam interactions
document.getElementById('stage').addEventListener('click', ()=> setAnalyzeEnabled(hasPixels()));
document.getElementById('file').addEventListener('input', ()=> setAnalyzeEnabled(hasPixels()));

}); // end DOMContentLoaded
</script>
</body>
</html>
