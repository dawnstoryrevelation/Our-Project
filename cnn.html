<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>B-Eye-O-Marker — CNN-V2 (BiNLOP-3)</title>
<meta name="description" content="Accessible web interface for B-Eye-O-Marker CNN-V2 (BiNLOP-3) ONNX: detect, diagnose and identify potential eye ailments from camera or photos, with full TTS."/>
<style>
  :root{
    --bg:#0f1222; --panel:#151936; --panel-2:#1b2147; --text:#e9ecff; --muted:#b9c1ff;
    --accent:#7aa2ff; --accent-2:#63e6be; --danger:#ff6b6b; --ok:#94f3a2; --warn:#ffd166;
    --focus:#ffe08a; --border:#2c3366; --shadow:0 10px 30px rgba(0,0,0,.35);
  }
  @media (prefers-color-scheme: light){
    :root{ --bg:#f6f8ff; --panel:#ffffff; --panel-2:#f2f4ff; --text:#111320; --muted:#3b3f66; --border:#d8dcff; --shadow:0 10px 30px rgba(0,0,0,.08);}
  }
  html,body{margin:0;padding:0;background:linear-gradient(180deg,var(--bg),#0b0e1b);color:var(--text);font-family:system-ui,-apple-system,Segoe UI,Roboto,Inter,Arial,sans-serif;line-height:1.5}
  a{color:var(--accent)}
  .wrap{max-width:1200px;margin:0 auto;padding:16px}
  .skip{position:absolute;left:-9999px;top:auto;width:1px;height:1px;overflow:hidden}
  .skip:focus{position:fixed;left:16px;top:16px;width:auto;height:auto;background:var(--panel);color:var(--text);padding:8px 12px;border-radius:8px;box-shadow:var(--shadow);outline:3px solid var(--focus)}
  header{display:grid;gap:12px;align-items:center;margin:16px 0;padding:16px;border:1px solid var(--border);background:radial-gradient(1200px 400px at 20% -20%, rgba(122,162,255,.25), transparent 60%), var(--panel);border-radius:18px;box-shadow:var(--shadow)}
  header h1{margin:0;font-size:clamp(22px,4vw,36px)}
  header p{margin:0;color:var(--muted)}
  header .controls{display:flex;flex-wrap:wrap;gap:10px;align-items:center}
  .btn, button, input[type=file]::file-selector-button{
    background:var(--accent);color:#0b0d1a;border:none;padding:10px 14px;border-radius:12px;font-weight:600;cursor:pointer;
  }
  .btn.secondary{background:var(--panel-2);color:var(--text);border:1px solid var(--border)}
  .btn.danger{background:var(--danger);color:#fff}
  .btn:focus{outline:3px solid var(--focus)}
  .grid{display:grid;grid-template-columns:repeat(12,1fr);gap:16px}
  .card{grid-column:span 12;background:var(--panel);border:1px solid var(--border);border-radius:16px;padding:16px;box-shadow:var(--shadow)}
  @media(min-width:900px){
    .card.half{grid-column:span 6}
    .card.third{grid-column:span 4}
  }
  .card h2{margin:.2rem 0 0.4rem;font-size:1.25rem}
  .muted{color:var(--muted)}
  .row{display:flex;flex-wrap:wrap;gap:10px;align-items:center}
  .mode-tabs{display:flex;gap:6px;flex-wrap:wrap}
  .mode-tabs button{background:var(--panel-2);border:1px solid var(--border);color:var(--text)}
  .mode-tabs button[aria-selected="true"]{background:var(--accent-2);color:#002414}
  .sr-only{position:absolute;left:-9999px;top:auto;width:1px;height:1px;overflow:hidden}
  .label{font-weight:600}
  .bar{height:12px;background:var(--panel-2);border-radius:999px;overflow:hidden;border:1px solid var(--border)}
  .bar>span{display:block;height:100%;background:linear-gradient(90deg,var(--accent),var(--accent-2));width:0%}
  .live{border-left:4px solid var(--accent);padding-left:10px}
  .danger{color:var(--danger)} .ok{color:var(--ok)} .warn{color:var(--warn)}
  figure{margin:0}
  figcaption{color:var(--muted);font-size:.9rem;margin-top:4px}
  table{width:100%;border-collapse:separate;border-spacing:0 8px}
  th,td{padding:8px 12px;border-bottom:1px dashed var(--border)}
  th{text-align:left}
  .footer{color:var(--muted);font-size:.9rem;margin:20px 0}
  .pill{display:inline-block;padding:4px 8px;border-radius:999px;background:var(--panel-2);border:1px solid var(--border);margin-right:6px}
  .danger-bg{background:rgba(255,107,107,.08)}
  .notice{padding:10px;border-radius:12px;border:1px solid var(--border);background:var(--panel-2)}
  .chart-wrap{position:relative;height:260px}
  .controls select, .controls input[type=range]{background:var(--panel-2);color:var(--text);border:1px solid var(--border);padding:8px;border-radius:10px}
  .kbd{font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;background:var(--panel-2);border:1px solid var(--border);border-radius:6px;padding:2px 6px}
</style>
</head>
<body>
<a class="skip" href="#main">Skip to main content</a>

<header role="banner" aria-label="B-Eye-O-Marker header">
  <div class="wrap">
    <h1 id="title">B-Eye-O-Marker — CNN-V2 (BiNLOP-3)</h1>
    <p class="muted">Accessible in-browser eye-condition screening with your ONNX model. <span class="pill">Local</span> <span class="pill">Private</span> <span class="pill">TTS-ready</span></p>
    <div class="controls" aria-label="Global controls">
      <button class="btn" id="btnLoadDefault" aria-describedby="modelHelp">Load default ONNX</button>
      <input type="file" id="onnxFile" accept=".onnx" aria-label="Load ONNX from file"/>
      <button class="btn secondary" id="btnUnload">Unload model</button>
      <span id="modelHelp" class="muted">Default path: <code>B-Eye-O-Marker_CNN-V2.onnx</code></span>
    </div>
    <div class="controls" aria-label="Text to speech controls">
      <label for="ttsToggle"><span class="label">TTS</span></label>
      <select id="voiceSelect" aria-label="Choose TTS voice"></select>
      <label for="rate">Rate</label>
      <input id="rate" type="range" min="0.7" max="1.4" step="0.05" value="1" />
      <label for="pitch">Pitch</label>
      <input id="pitch" type="range" min="0.8" max="1.2" step="0.05" value="1" />
      <button class="btn secondary" id="btnReadAll">Read all visible content</button>
      <span class="muted">Keyboard: <span class="kbd">R</span>=Read, <span class="kbd">/</span>=Focus search</span>
    </div>
    <div class="notice" role="note">
      <strong>Important:</strong> This tool is a research prototype, <span class="danger">not</span> a medical device. It does not provide medical advice. If you have symptoms or concerns, seek professional care.
    </div>
  </div>
</header>

<main id="main" class="wrap" role="main">
  <section class="card" aria-labelledby="modes-h2">
    <h2 id="modes-h2">Choose a mode</h2>
    <div class="mode-tabs" role="tablist" aria-label="Input modes">
      <button role="tab" id="tab-camera" aria-selected="true" aria-controls="panel-camera" class="btn secondary">Camera</button>
      <button role="tab" id="tab-upload" aria-selected="false" aria-controls="panel-upload" class="btn secondary">Upload Photo</button>
      <button role="tab" id="tab-manual" aria-selected="false" aria-controls="panel-manual" class="btn secondary">Manual</button>
    </div>
  </section>

  <!-- CAMERA -->
  <section id="panel-camera" role="tabpanel" aria-labelledby="tab-camera" class="card">
    <h2>Camera</h2>
    <p class="muted">Allow camera access, center your eye(s) in the frame, then capture a photo.</p>
    <div class="grid">
      <div class="card half">
        <h3>Live Preview</h3>
        <div class="row">
          <button class="btn" id="startCam">Start camera</button>
          <button class="btn" id="capture" disabled>Capture</button>
          <button class="btn secondary" id="stopCam" disabled>Stop</button>
        </div>
        <figure>
          <video id="video" playsinline autoplay muted width="100%" style="max-width:100%;border-radius:12px;border:1px solid var(--border)"></video>
          <figcaption id="camStatus" class="muted" aria-live="polite">Camera off.</figcaption>
        </figure>
        <p class="muted">Tip: use good lighting and keep still. FPS: <span id="fps" aria-live="polite">0</span></p>
      </div>
      <div class="card half">
        <h3>Captured Frame</h3>
        <div class="row">
          <button class="btn" id="analyzeCam" disabled>Analyze</button>
          <button class="btn secondary" id="downloadFrame" disabled>Download frame</button>
          <button class="btn secondary" id="speakCamera">Speak</button>
        </div>
        <canvas id="captureCanvas" width="384" height="384" style="width:100%;border-radius:12px;border:1px solid var(--border)"></canvas>
        <p class="muted">Preprocess: center-crop to square → resize 384×384 → normalize [0,1].</p>
      </div>
    </div>
  </section>

  <!-- UPLOAD -->
  <section id="panel-upload" role="tabpanel" aria-labelledby="tab-upload" class="card" hidden>
    <h2>Upload photo</h2>
    <div class="row">
      <input type="file" id="fileInput" accept="image/*" aria-label="Choose an eye photo to analyze" />
      <button class="btn" id="analyzeFile" disabled>Analyze</button>
      <button class="btn secondary" id="speakUpload">Speak</button>
    </div>
    <div class="grid">
      <div class="card half">
        <h3>Preview</h3>
        <img id="preview" alt="Uploaded image preview" style="max-width:100%;border-radius:12px;border:1px solid var(--border)"/>
      </div>
      <div class="card half">
        <h3>Preprocessed</h3>
        <canvas id="fileCanvas" width="384" height="384" style="width:100%;border-radius:12px;border:1px solid var(--border)"></canvas>
      </div>
    </div>
  </section>

  <!-- MANUAL -->
  <section id="panel-manual" role="tabpanel" aria-labelledby="tab-manual" class="card" hidden>
    <h2>Manual mode</h2>
    <p class="muted">Pick a condition to view guidance without running the CNN.</p>
    <div class="row">
      <label for="manualSelect" class="label">Condition</label>
      <select id="manualSelect" aria-label="Select a condition">
        <option value="">Select…</option>
        <option>Normal</option>
        <option>DiabeticRetinopathy</option>
        <option>DiabeticMacularEdema</option>
        <option>AgeRelatedMacularDegeneration</option>
        <option>Glaucoma</option>
        <option>RetinalDetachment</option>
        <option>EpiretinalMembrane</option>
        <option>VitreousDetachment</option>
        <option>Other</option>
      </select>
      <button class="btn" id="manualShow">Show guidance</button>
      <button class="btn secondary" id="speakManual">Speak</button>
    </div>
  </section>

  <!-- RESULTS -->
  <section id="results" class="card live danger-bg" aria-live="polite" aria-atomic="true">
    <h2>Results</h2>
    <div id="summary" class="notice" role="status">No results yet. Load model and analyze an image, or choose Manual.</div>
    <div class="grid" aria-label="Outputs">
      <div class="card third">
        <h3>Top prediction</h3>
        <p id="topPred" class="ok" style="font-weight:700">—</p>
        <p class="muted">Confidence: <span id="topConf">—</span></p>
        <button class="btn secondary" data-say="#topPred">Speak</button>
      </div>
      <div class="card third">
        <h3>Probability distribution</h3>
        <div class="chart-wrap">
          <canvas id="probChart" aria-label="Probability chart" role="img"></canvas>
        </div>
        <details>
          <summary>Open accessible table</summary>
          <div id="probTableWrap" aria-live="polite"></div>
        </details>
        <button class="btn secondary" data-say="#probTableWrap">Speak</button>
      </div>
      <div class="card third">
        <h3>Metrics</h3>
        <ul>
          <li>Preprocess: <span id="mPre">—</span> ms</li>
          <li>Inference: <span id="mInf">—</span> ms</li>
          <li>Total: <span id="mTot">—</span> ms</li>
          <li>Backend: <span id="backend">—</span></li>
          <li>Input: <span id="inShape">—</span></li>
        </ul>
        <div class="row">
          <button class="btn secondary" id="btnSpeakMetrics">Speak</button>
          <button class="btn" id="btnExport">Download JSON report</button>
        </div>
      </div>
    </div>
  </section>

  <!-- GUIDANCE -->
  <section id="guidance" class="card" aria-labelledby="guidance-h2">
    <h2 id="guidance-h2">Recommendations & overview</h2>
    <article id="guidanceText">
      <p class="muted">You’ll see tailored recommendations here after a result (or via Manual mode). This section is fully TTS compatible.</p>
    </article>
    <div class="row">
      <button class="btn secondary" id="btnSpeakGuidance">Speak</button>
    </div>
  </section>

  <section class="footer" role="contentinfo">
    <p>Privacy: All images and inference run locally in your browser. No uploads.</p>
    <p>Medical disclaimer: This interface is for information only and is not a substitute for professional diagnosis or treatment.</p>
  </section>
</main>

<!-- Dependencies (CDN). If blocked, you can run without charts; core works without them. -->
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js"></script>

<script>
/* ========================= Config & globals ========================= */
const DEFAULT_MODEL = "B-Eye-O-Marker_CNN-V2.onnx";
const LABELS = [
  "Normal","DiabeticRetinopathy","DiabeticMacularEdema","AgeRelatedMacularDegeneration",
  "Glaucoma","RetinalDetachment","EpiretinalMembrane","VitreousDetachment","Other"
];
const IMG_SIZE = 384; const INPUT_CH = 3;
let session = null; let backendName = "—"; let probChart = null;
let voices = []; const ttsState = { rate: 1.0, pitch: 1.0, voice: null };

/* ========================= Accessibility: TTS ========================= */
function populateVoices(){
  voices = window.speechSynthesis.getVoices().filter(v => v.lang.toLowerCase().startsWith("en"));
  const sel = document.getElementById("voiceSelect");
  sel.innerHTML = "";
  voices.forEach((v, i) => {
    const opt = document.createElement("option");
    opt.value = i; opt.textContent = `${v.name} (${v.lang})${v.default ? " — default":""}`;
    sel.appendChild(opt);
  });
  if(voices.length) { sel.selectedIndex = 0; ttsState.voice = voices[0]; }
}
window.speechSynthesis.onvoiceschanged = populateVoices;
document.addEventListener("DOMContentLoaded", populateVoices);

function speak(text){
  if(!('speechSynthesis' in window)) return;
  const u = new SpeechSynthesisUtterance(text);
  if(ttsState.voice) u.voice = ttsState.voice;
  u.rate = ttsState.rate; u.pitch = ttsState.pitch;
  window.speechSynthesis.cancel(); // ensure fresh
  window.speechSynthesis.speak(u);
}
function speakEl(selector){
  const el = typeof selector==="string" ? document.querySelector(selector) : selector;
  if(!el) return;
  // Gather visible text including table cells
  const walker = document.createTreeWalker(el, NodeFilter.SHOW_TEXT, null);
  let txt = "";
  while(walker.nextNode()){ const t = walker.currentNode.nodeValue.trim(); if(t) txt += t + " "; }
  speak(txt);
}
document.getElementById("voiceSelect").addEventListener("change", e=>{
  const idx = parseInt(e.target.value||"0",10); ttsState.voice = voices[idx] || null;
});
document.getElementById("rate").addEventListener("input", e=> ttsState.rate = parseFloat(e.target.value));
document.getElementById("pitch").addEventListener("input", e=> ttsState.pitch = parseFloat(e.target.value));
document.getElementById("btnReadAll").addEventListener("click", ()=>{
  const main = document.getElementById("main"); speakEl(main);
});
document.addEventListener("keydown", e=>{
  if(e.key==="r" || e.key==="R"){ e.preventDefault(); speakEl("#results"); }
  if(e.key==="/"){ e.preventDefault(); (document.querySelector("input[type='file']")||document.body).focus(); }
});

/* ========================= UI Tabs ========================= */
const tabs = [
  {tab:"#tab-camera", panel:"#panel-camera"},
  {tab:"#tab-upload", panel:"#panel-upload"},
  {tab:"#tab-manual", panel:"#panel-manual"}
];
tabs.forEach(({tab,panel})=>{
  document.querySelector(tab).addEventListener("click", ()=>{
    tabs.forEach(({tab:t,panel:p})=>{
      document.querySelector(t).setAttribute("aria-selected", t===tab ? "true":"false");
      document.querySelector(p).hidden = p!==panel;
    });
  });
});

/* ========================= Utility: images & preprocessing ========================= */
function drawSquareToCanvas(img, canvas){
  const ctx = canvas.getContext("2d", { willReadFrequently: true });
  const size = Math.min(img.naturalWidth||img.videoWidth, img.naturalHeight||img.videoHeight);
  const sx = ((img.naturalWidth||img.videoWidth) - size)/2;
  const sy = ((img.naturalHeight||img.videoHeight) - size)/2;
  canvas.width = IMG_SIZE; canvas.height = IMG_SIZE;
  ctx.clearRect(0,0,canvas.width,canvas.height);
  ctx.drawImage(img, sx, sy, size, size, 0, 0, IMG_SIZE, IMG_SIZE);
}
function tensorFromCanvas(canvas){
  // Canvas RGBA → Float32 CHW in [0,1]
  const ctx = canvas.getContext("2d", { willReadFrequently: true });
  const { data } = ctx.getImageData(0,0,canvas.width,canvas.height);
  const W = canvas.width, H = canvas.height;
  const out = new Float32Array(1 * INPUT_CH * H * W);
  // CHW order
  let rOfs = 0, gOfs = H*W, bOfs = 2*H*W;
  for(let y=0;y<H;y++){
    for(let x=0;x<W;x++){
      const idx = (y*W + x)*4;
      const r = data[idx]/255, g = data[idx+1]/255, b = data[idx+2]/255;
      const i = y*W + x;
      out[rOfs + i] = r; out[gOfs + i] = g; out[bOfs + i] = b;
    }
  }
  return out;
}
function sigmoid(x){ return 1/(1+Math.exp(-x)); }

/* ========================= Model load / unload ========================= */
async function loadDefaultModel(){
  try{
    announce("Loading default ONNX model…");
    session = await ort.InferenceSession.create(DEFAULT_MODEL, {
      executionProviders: ['webgl','wasm'], // prefer WebGL, fallback to WASM
      graphOptimizationLevel: "all"
    });
    backendName = (await session.executionProvider).toString();
    document.getElementById("backend").textContent = backendName;
    announce("Model loaded.");
  }catch(err){
    console.warn(err);
    alert("Could not fetch default ONNX (CORS or missing file). Use 'Load ONNX from file'.");
  }
}
async function loadFromFile(file){
  const buf = await file.arrayBuffer();
  session = await ort.InferenceSession.create(buf, { executionProviders: ['webgl','wasm'], graphOptimizationLevel: "all" });
  backendName = (await session.executionProvider).toString();
  document.getElementById("backend").textContent = backendName;
  announce("Model loaded from file.");
}
function unloadModel(){
  session = null;
  document.getElementById("backend").textContent = "—";
  announce("Model unloaded.");
}
document.getElementById("btnLoadDefault").addEventListener("click", loadDefaultModel);
document.getElementById("onnxFile").addEventListener("change", e=>{
  const f = e.target.files?.[0]; if(f) loadFromFile(f);
});
document.getElementById("btnUnload").addEventListener("click", unloadModel);

/* ========================= Results UI helpers ========================= */
function announce(s){
  const sum = document.getElementById("summary");
  sum.textContent = s;
  speak(s); // always SR-friendly
}
function updateProbChart(probs){
  const ctx = document.getElementById("probChart").getContext("2d");
  const data = { labels: LABELS, datasets: [{ label:"Probability", data: probs.map(v=>+v.toFixed(4)) }]};
  const opts = { responsive:true, maintainAspectRatio:false, scales:{ y:{ beginAtZero:true, max:1 }}, plugins:{ legend:{ display:false }, tooltip:{ enabled:true }}, animation:{ duration:300 } };
  if(probChart){ probChart.data = data; probChart.update(); }
  else { probChart = new Chart(ctx, { type:"bar", data, options:opts }); }
  // Accessible table mirror
  const wrap = document.getElementById("probTableWrap");
  const table = document.createElement("table"); table.setAttribute("aria-label","Probability table");
  const thead = document.createElement("thead"); const trh = document.createElement("tr");
  ["Condition","Probability"].forEach(h=>{ const th=document.createElement("th"); th.textContent=h; trh.appendChild(th); });
  thead.appendChild(trh);
  const tbody = document.createElement("tbody");
  LABELS.forEach((lab,i)=>{
    const tr = document.createElement("tr");
    const td1 = document.createElement("td"); td1.textContent = lab;
    const td2 = document.createElement("td"); td2.textContent = probs[i].toFixed(4);
    tr.append(td1,td2); tbody.appendChild(tr);
  });
  table.append(thead,tbody);
  wrap.innerHTML=""; wrap.appendChild(table);
}
function showBars(probs){
  const topIdx = probs.reduce((bi, v, i)=> v > probs[bi] ? i : bi, 0);
  document.getElementById("topPred").textContent = LABELS[topIdx];
  document.getElementById("topConf").textContent = (probs[topIdx]*100).toFixed(2)+"%";
}

/* ========================= Guidance (condition-specific) ========================= */
const GUIDANCE = {
  "Normal": {
    summary: "No clear signs of listed pathologies detected.",
    actions: [
      "Maintain regular eye exams per your optometrist’s schedule.",
      "Protect eyes from UV using sunglasses.",
      "Manage systemic risks (blood pressure, glucose, lipids)."
    ],
    notes: "If you have symptoms (sudden floaters, flashes, vision loss), seek care urgently regardless of this screening."
  },
  "DiabeticRetinopathy": {
    summary: "Signs suggestive of diabetic retinopathy (DR).",
    actions: [
      "Schedule a dilated retinal exam with an ophthalmologist.",
      "Tighten glucose control (HbA1c target individualized).",
      "Discuss blood pressure & lipid management with your clinician."
    ],
    notes: "Treatment ranges from observation to anti-VEGF injections or laser, depending on severity."
  },
  "DiabeticMacularEdema": {
    summary: "Features may indicate diabetic macular edema (DME).",
    actions: [
      "Prompt evaluation by a retina specialist is recommended.",
      "Discuss anti-VEGF or steroid options; systemic control remains critical."
    ],
    notes: "Macular edema risks central vision—timely treatment matters."
  },
  "AgeRelatedMacularDegeneration": {
    summary: "Possible age-related macular degeneration (AMD).",
    actions: [
      "Arrange OCT and dilated exam; consider AREDS2 vitamins (non-smokers) if intermediate AMD.",
      "Avoid smoking; monitor with an Amsler grid; ensure blue-light/UV protection."
    ],
    notes: "Wet AMD may need urgent anti-VEGF; dry AMD needs risk control and monitoring."
  },
  "Glaucoma": {
    summary: "Findings may be consistent with glaucoma risk.",
    actions: [
      "Comprehensive glaucoma workup (IOP, pachymetry, gonioscopy, RNFL OCT, visual fields).",
      "Adherence to drops if prescribed; discuss target pressures."
    ],
    notes: "Glaucoma is usually asymptomatic until late—follow-up is vital."
  },
  "RetinalDetachment": {
    summary: "Possible retinal detachment risk pattern.",
    actions: [
      "This can be vision-threatening—seek same-day evaluation if symptomatic.",
      "Avoid strenuous activity until cleared by a clinician."
    ],
    notes: "Symptoms include curtain-like shadow, flashes, sudden floaters."
  },
  "EpiretinalMembrane": {
    summary: "Potential epiretinal membrane (ERM).",
    actions: [
      "Schedule evaluation; mild cases may be observed, significant distortion may need surgery.",
      "Track visual distortion (Amsler) and symptoms."
    ],
    notes: "Surgical peeling is considered if function is impacted."
  },
  "VitreousDetachment": {
    summary: "Possible posterior vitreous detachment.",
    actions: [
      "If new onset floaters/flashes, rule out retinal tears; otherwise observe.",
      "Return sooner for any sudden symptom change."
    ],
    notes: "Most PVD is benign but can be associated with retinal breaks."
  },
  "Other": {
    summary: "Uncategorized or unclear pattern.",
    actions: [
      "Obtain clinician assessment to refine diagnosis.",
      "Ensure high-quality imaging and history are reviewed."
    ],
    notes: "Model outputs are limited by image quality and scope of training."
  }
};
function renderGuidance(label){
  const g = GUIDANCE[label] || GUIDANCE["Other"];
  const el = document.getElementById("guidanceText");
  el.innerHTML = `
    <h3>${label}</h3>
    <p><strong>Summary:</strong> ${g.summary}</p>
    <ul>${g.actions.map(a=>`<li>${a}</li>`).join("")}</ul>
    <p class="muted"><strong>Notes:</strong> ${g.notes}</p>
  `;
}

/* ========================= Inference ========================= */
async function runInferenceFromCanvas(canvas){
  if(!session){ announce("Load a model first."); return; }
  const t0 = performance.now();
  const inputData = tensorFromCanvas(canvas);
  const pre = performance.now() - t0;

  const W = IMG_SIZE, H = IMG_SIZE, C = INPUT_CH;
  const tensor = new ort.Tensor('float32', inputData, [1,C,H,W]);
  const feeds = {};
  // auto-detect input name
  const inp = session.inputNames ? session.inputNames[0] : "input";
  feeds[inp] = tensor;

  const t1 = performance.now();
  const out = await session.run(feeds);
  const inf = performance.now() - t1;

  // auto-detect output name
  const outName = session.outputNames ? session.outputNames[0] : Object.keys(out)[0];
  const logits = out[outName].data;
  // multi-label: sigmoid
  const probs = Array.from(logits).map(sigmoid);
  const tot = performance.now() - t0;

  // update UI
  document.getElementById("mPre").textContent = pre.toFixed(2);
  document.getElementById("mInf").textContent = inf.toFixed(2);
  document.getElementById("mTot").textContent = tot.toFixed(2);
  document.getElementById("inShape").textContent = `1×${C}×${H}×${W}`;
  updateProbChart(probs);
  showBars(probs);
  renderGuidance(LABELS[probs.indexOf(Math.max(...probs))]);
  announce("Inference complete. See results below.");
  return { probs, pre, inf, tot };
}

/* ========================= Camera mode ========================= */
let stream = null, rafId = null, lastFrameTime = performance.now(), fps=0;
async function startCamera(){
  try{
    stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode:"user", width:{ideal:1280}, height:{ideal:720} }, audio:false });
    const video = document.getElementById("video");
    video.srcObject = stream;
    document.getElementById("camStatus").textContent = "Camera on. Position your eye(s), then capture.";
    document.getElementById("capture").disabled = false;
    document.getElementById("stopCam").disabled = false;
    // FPS estimator
    const tick = ()=>{
      const now = performance.now();
      const dt = now - lastFrameTime; lastFrameTime = now;
      fps = 1000/dt;
      document.getElementById("fps").textContent = fps.toFixed(1);
      rafId = requestAnimationFrame(tick);
    };
    rafId = requestAnimationFrame(tick);
  }catch(e){
    alert("Camera not available or permission denied.");
  }
}
function stopCamera(){
  if(rafId) cancelAnimationFrame(rafId);
  if(stream){ stream.getTracks().forEach(t=>t.stop()); stream=null; }
  document.getElementById("video").srcObject = null;
  document.getElementById("camStatus").textContent = "Camera off.";
  document.getElementById("capture").disabled = true;
  document.getElementById("stopCam").disabled = true;
  document.getElementById("analyzeCam").disabled = true;
}
function captureFrame(){
  const video = document.getElementById("video");
  const canvas = document.getElementById("captureCanvas");
  drawSquareToCanvas(video, canvas);
  document.getElementById("analyzeCam").disabled = false;
  document.getElementById("downloadFrame").disabled = false;
}
function downloadFrame(){
  const link = document.createElement('a');
  link.download = 'eye_capture.png';
  link.href = document.getElementById("captureCanvas").toDataURL("image/png");
  link.click();
}
document.getElementById("startCam").addEventListener("click", startCamera);
document.getElementById("stopCam").addEventListener("click", stopCamera);
document.getElementById("capture").addEventListener("click", captureFrame);
document.getElementById("downloadFrame").addEventListener("click", downloadFrame);
document.getElementById("analyzeCam").addEventListener("click", async ()=>{
  await runInferenceFromCanvas(document.getElementById("captureCanvas"));
});
document.getElementById("speakCamera").addEventListener("click", ()=> speakEl("#panel-camera"));

/* ========================= Upload mode ========================= */
const fileInput = document.getElementById("fileInput");
fileInput.addEventListener("change", ()=>{
  const f = fileInput.files?.[0];
  if(!f) return;
  const url = URL.createObjectURL(f);
  const img = document.getElementById("preview");
  img.onload = ()=>{
    drawSquareToCanvas(img, document.getElementById("fileCanvas"));
    document.getElementById("analyzeFile").disabled = false;
    URL.revokeObjectURL(url);
  };
  img.src = url;
});
document.getElementById("analyzeFile").addEventListener("click", async ()=>{
  await runInferenceFromCanvas(document.getElementById("fileCanvas"));
});
document.getElementById("speakUpload").addEventListener("click", ()=> speakEl("#panel-upload"));

/* ========================= Manual mode ========================= */
document.getElementById("manualShow").addEventListener("click", ()=>{
  const v = document.getElementById("manualSelect").value;
  if(!v){ announce("Pick a condition first."); return; }
  const probs = LABELS.map(l=> l===v ? 0.95 : 0.05/(LABELS.length-1));
  updateProbChart(probs);
  showBars(probs);
  renderGuidance(v);
  document.getElementById("mPre").textContent = "—";
  document.getElementById("mInf").textContent = "—";
  document.getElementById("mTot").textContent = "—";
  document.getElementById("inShape").textContent = "manual";
  announce(`Manual: ${v}. Showing guidance.`);
});
document.getElementById("speakManual").addEventListener("click", ()=> speakEl("#panel-manual"));

/* ========================= Speak buttons in results/guidance ========================= */
document.getElementById("btnSpeakMetrics").addEventListener("click", ()=>{
  const s = `Preprocess ${document.getElementById("mPre").textContent} milliseconds. `+
            `Inference ${document.getElementById("mInf").textContent} milliseconds. `+
            `Total ${document.getElementById("mTot").textContent} milliseconds. `+
            `Backend ${document.getElementById("backend").textContent}. Input shape ${document.getElementById("inShape").textContent}.`;
  speak(s);
});
document.getElementById("btnSpeakGuidance").addEventListener("click", ()=> speakEl("#guidanceText"));
document.querySelectorAll("[data-say]").forEach(btn=>{
  btn.addEventListener("click", ()=> speakEl(btn.getAttribute("data-say")));
});

/* ========================= JSON report export ========================= */
document.getElementById("btnExport").addEventListener("click", ()=>{
  const table = document.querySelector("#probTableWrap table");
  const rows = table ? Array.from(table.querySelectorAll("tbody tr")).map(tr=>{
    const tds = tr.querySelectorAll("td");
    return { label: tds[0].textContent, probability: parseFloat(tds[1].textContent) };
  }) : [];
  const payload = {
    model: backendName,
    top: document.getElementById("topPred").textContent,
    top_confidence: document.getElementById("topConf").textContent,
    metrics: {
      preprocess_ms: document.getElementById("mPre").textContent,
      inference_ms: document.getElementById("mInf").textContent,
      total_ms: document.getElementById("mTot").textContent,
      input: document.getElementById("inShape").textContent
    },
    distribution: rows,
    timestamp: new Date().toISOString()
  };
  const blob = new Blob([JSON.stringify(payload,null,2)], {type:"application/json"});
  const a = document.createElement("a"); a.href = URL.createObjectURL(blob); a.download = "b-eye-o-marker_report.json"; a.click();
  URL.revokeObjectURL(a.href);
});
</script>
</body>
</html>
